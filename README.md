# ğŸï¸ Smart Motorcycle Traffic Violation Detection System

AI-powered traffic violation detection using **dual YOLOv8 models** and **EasyOCR**. This system detects helmet violations, per-motorcycle triple riding, and extracts license plate numbers from images and videos through a professional Streamlit web interface.

![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B?logo=streamlit&logoColor=white)
![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-00FFFF?logo=yolo&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ§  Model Training

The custom YOLOv8 model was trained on Google Colab using a curated dataset of motorcycle traffic images.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/S07singh/Smart-Motorcycle-Traffic-Violation-Detection-System/blob/main/Smart_Motorcycle_Traffic_Violation_Detection_System.ipynb)

---

## âœ¨ Features

- **Dual YOLOv8 Detection** â€” Custom model for helmet/person/plate + pretrained COCO model for motorcycle detection.
- **Per-Motorcycle Triple Riding** â€” Center-based person-motorcycle spatial association instead of naive global person count.
- **No Helmet Detection** â€” Flags riders without helmets with per-detection confidence scores.
- **Enhanced License Plate OCR** â€” Multi-stage preprocessing (upscale â†’ adaptive threshold â†’ morphological cleanup) + Indian plate regex validation.
- **Image & Video Support** â€” Upload JPG/PNG images or MP4/AVI/MOV/MKV videos for analysis.
- **Interactive Confidence Tuning** â€” Adjust the detection threshold via a sidebar slider.
- **Structured Violation Reports** â€” Summary metrics, violation cards, detailed logs, and plate OCR details.
- **Production-Ready UI** â€” Modern Streamlit interface with custom CSS styling.

---

## ğŸ“ Project Structure

```
Smart Motorcycle Traffic Violation Detection System/
â”œâ”€â”€ app.py                     # Main Streamlit application
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ LICENSE                    # MIT License
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ Smart_Motorcycle_Traffic_Violation_Detection_System.ipynb  # Training notebook
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ best.pt                # Custom trained YOLOv8 weights
â”‚   â””â”€â”€ yolov8n.pt             # Pretrained COCO YOLOv8n weights
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py            # Package init
â”‚   â”œâ”€â”€ detector.py            # Dual YOLO detection (custom + COCO motorcycle)
â”‚   â”œâ”€â”€ ocr_engine.py          # Enhanced OCR pipeline with preprocessing
â”‚   â”œâ”€â”€ violation_checker.py   # Per-motorcycle violation logic
â”‚   â””â”€â”€ visualizer.py          # Selective bounding box annotation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ classes.txt            # Class names
â”‚   â”œâ”€â”€ traffic.yaml           # YOLO training config
â”‚   â”œâ”€â”€ train/                 # Training images & labels
â”‚   â””â”€â”€ val/                   # Validation images & labels
â””â”€â”€ test/                      # Test images
```

---

## ğŸš€ Quick Start

### 1. Clone the repository

```bash
git clone https://github.com/S07singh/Smart-Motorcycle-Traffic-Violation-Detection-System.git
cd Smart-Motorcycle-Traffic-Violation-Detection-System
```

### 2. Create a virtual environment (recommended)

```bash
python -m venv env
# Windows
env\Scripts\activate
# Linux/macOS
source env/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Place the model weights

- **Custom model:** Place your trained YOLOv8 weights at `model/best.pt`.
- **COCO model:** Place `yolov8n.pt` at `model/yolov8n.pt` (download from [Ultralytics](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)).

### 5. Run the application

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`.

---

## ğŸ¯ How It Works

### Detection Pipeline

```
Input Frame
    â”‚
    â”œâ”€â”€â–º Custom YOLOv8 â”€â”€â–º helmet, no_helmet, person, license_plate
    â”‚
    â””â”€â”€â–º COCO YOLOv8n  â”€â”€â–º motorcycle
              â”‚
              â–¼
     Per-Motorcycle Association (center-based)
              â”‚
              â–¼
     Violation Report + Annotated Image + OCR Results
```

1. **Upload** â€” User uploads an image or video through the Streamlit interface.
2. **Dual-Model Inference** â€” Two YOLOv8 models run in parallel:
   - **Custom model** â†’ detects helmets, no-helmet riders, persons, and license plates.
   - **COCO model** â†’ detects motorcycles (class 3).
3. **Triple Riding Check** â€” For each motorcycle, persons are associated using center-point-in-bbox matching. If a motorcycle has >2 associated persons, it is flagged.
4. **No Helmet Check** â€” Any `no_helmet` detection triggers a helmet violation.
5. **OCR Extraction** â€” Detected plates are preprocessed (2-3x upscale â†’ adaptive threshold â†’ morphological cleanup) and read using EasyOCR, then cleaned with Indian plate regex `[A-Z]{2}\d{2}[A-Z]{1,2}\d{4}`.
6. **Visualisation** â€” Color-coded bounding boxes:
   - ğŸŸ¢ Green â€” helmet
   - ğŸ”´ Red â€” no helmet / violating motorcycle / violating persons
   - ğŸŸ  Orange â€” person (non-violating)
   - ğŸŸ¡ Cyan â€” motorcycle (safe) / license plate
7. **Report** â€” Structured violation report with metrics, violation cards, plate OCR details, and detection logs.

### Classes Detected

| Model | Class ID | Class Name | Description |
|-------|----------|------------|-------------|
| Custom | 0 | `helmet` | Rider wearing a helmet |
| Custom | 1 | `no_helmet` | Rider without a helmet |
| Custom | 2 | `person` | Person on/near motorcycle |
| Custom | 3 | `license_plate` | Vehicle license plate |
| COCO | 3 | `motorcycle` | Motorcycle vehicle |

### OCR Preprocessing Pipeline

| Step | Technique | Purpose |
|------|-----------|---------|
| 1 | Bicubic upscale (2-3x) | Small plates need ~32px char height for OCR |
| 2 | Grayscale conversion | Reduces color noise |
| 3 | Adaptive Gaussian threshold | Handles uneven lighting â†’ clean B&W text |
| 4 | Morphological close + open | Fills char gaps, removes noise dots |
| 5 | Indian plate regex | Extracts valid `XX00XX0000` pattern from noisy OCR |

---

## âš™ï¸ Configuration

| Setting | Location | Default | Description |
|---------|----------|---------|-------------|
| Confidence Threshold | Sidebar slider | 0.25 | Min confidence for YOLO detections |
| OCR GPU | `utils/ocr_engine.py` | `False` | Set to `True` if CUDA GPU available |
| Custom Model Path | `app.py` | `model/best.pt` | Path to custom YOLOv8 weights |
| COCO Model Path | `app.py` | `model/yolov8n.pt` | Path to COCO YOLOv8n weights |

---

## â˜ï¸ Deploy on Streamlit Cloud

1. Push your repository to GitHub.
2. Go to [share.streamlit.io](https://share.streamlit.io).
3. Connect your GitHub repo and select `app.py` as the main file.
4. Ensure `model/best.pt` and `model/yolov8n.pt` are in the repo (use Git LFS for large files).
5. Deploy!

> **Note:** Streamlit Cloud provides CPU-only instances. The app is configured to run without GPU by default.

---

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| **Python 3.9+** | Core programming language |
| **Streamlit** | Web application framework |
| **Ultralytics YOLOv8** | Object detection (custom + COCO) |
| **OpenCV** | Image/video processing & plate preprocessing |
| **EasyOCR** | Optical character recognition |
| **NumPy** | Array operations |
| **Pillow** | Image format handling |

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“¬ Contact

For questions or suggestions, please open an issue on the GitHub repository.
